{"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9026977,"sourceType":"datasetVersion","datasetId":5440496}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marekbajdk/classifying-claims-and-opinions-in-tiktok-content?scriptVersionId=205248385\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"![](https://media.licdn.com/dms/image/D4D12AQGU_0vXNy2KcA/article-cover_image-shrink_720_1280/0/1691093307457?e=1726099200&v=beta&t=b9S9B1pijG6vw6ULCrb7JSOH9eqLXsKmIDDWQMPgBvM)","metadata":{}},{"cell_type":"markdown","source":"# **TikTok Claim Classification Project**\n\n","metadata":{}},{"cell_type":"markdown","source":"## **PACE: Plan**\n\n**Business Need and Modeling Objective**\n\nTikTok users can report videos they believe violate the platform's terms of service. Given the sheer volume of videos created and viewed daily, it's impractical for human moderators to review every reported video.\n\nAnalysis shows that videos violating the terms of service are more likely to present claims rather than opinions. Thus, distinguishing between videos that make claims and those that express opinions is crucial.\n\nTikTok aims to develop a machine learning model to identify claims and opinions in videos. Videos identified as opinions will be less likely to require human review. In contrast, videos identified as claims will undergo a further sorting process to prioritize those for human moderation. For instance, claim videos could be ranked by the number of reports they receive, with the top x% reviewed daily by human moderators.\n\nThis machine learning model will significantly enhance the efficiency of human moderators by presenting them with videos that are most likely to violate TikTok's terms of service.","metadata":{"id":"E5g1A74r0ow_"}},{"cell_type":"markdown","source":"**Modeling Design and Target Variable**\n\nThe dataset includes a column named claim_status, a binary indicator of whether a video is a claim or an opinion. This binary value will serve as the target variable for the model, which will predict whether each video is a claim or an opinion.\n\nThis task involves binary classification, as the model will classify videos into one of two categories.","metadata":{}},{"cell_type":"markdown","source":"**Selecting an Evaluation Metric**\n\nTo choose an appropriate evaluation metric, consider the types of prediction errors:\n\n- **False positives:** The model predicts a video is a claim when it is actually an opinion.\n- **False negatives:** The model predicts a video is an opinion when it is actually a claim.\n\nThe machine learning model will be instrumental in presenting human moderators with videos that are most likely to violate TikTok's terms of service.","metadata":{}},{"cell_type":"markdown","source":"**Modeling Workflow and Model Selection Process**\n\n   1. Split the data into training, validation, and test sets (60/20/20).\n   2. Fit models and tune hyperparameters using the training set.\n   3. Perform final model selection using the validation set.\n   4. Assess the performance of the chosen model on the test set.\n    \n\n![](https://raw.githubusercontent.com/adacert/tiktok/main/optimal_model_flow_numbered.svg)","metadata":{}},{"cell_type":"markdown","source":"### **Task 1. Imports and data loading**\n\nStart by importing packages needed to build machine learning models to achieve the goal of this project.","metadata":{"id":"e8Vm3QEfGELS"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Suppress the specific FutureWarning in Kaggle notebook\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"use_inf_as_na option is deprecated\")\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"When grouping with a length-1 list-like\")\n\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Displaying all of the columns in dataframes\npd.set_option('display.max_columns', None)\n\n# Data modeling\nfrom xgboost import XGBClassifier\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Data preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.utils import resample\n\n# Statistical analysis/hypothesis testing\nfrom scipy import stats\n\n# Metrics and helpful functions\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, \\\nrecall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.tree import plot_tree\n\n# For saving models\nimport pickle","metadata":{"id":"tCni9wAGphb0","execution":{"iopub.status.busy":"2024-08-03T16:42:03.021234Z","iopub.execute_input":"2024-08-03T16:42:03.021747Z","iopub.status.idle":"2024-08-03T16:42:03.033688Z","shell.execute_reply.started":"2024-08-03T16:42:03.021709Z","shell.execute_reply":"2024-08-03T16:42:03.032047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset into dataframe\ndata = pd.read_csv('/kaggle/input/tiktok-content/tiktok_video_metrics.csv') /kaggle/input/tiktok-content","metadata":{"id":"C9ODhaOppqlw","execution":{"iopub.status.busy":"2024-08-03T16:10:50.370079Z","iopub.execute_input":"2024-08-03T16:10:50.370495Z","iopub.status.idle":"2024-08-03T16:10:50.472718Z","shell.execute_reply.started":"2024-08-03T16:10:50.370461Z","shell.execute_reply":"2024-08-03T16:10:50.471453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **PACE: Analyze**","metadata":{}},{"cell_type":"markdown","source":"### **Understanding and inspecting data**","metadata":{}},{"cell_type":"code","source":"# Display and examine the first ten rows of the dataframe\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.47436Z","iopub.execute_input":"2024-08-03T16:10:50.474812Z","iopub.status.idle":"2024-08-03T16:10:50.505731Z","shell.execute_reply.started":"2024-08-03T16:10:50.474772Z","shell.execute_reply":"2024-08-03T16:10:50.504428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each row represents a record for a particular ID or user's claim, containing detailed information about the video, duration, views, likes, shares, downloads, and comments. The dataset includes a mix of categorical, text, and numerical data.","metadata":{}},{"cell_type":"code","source":"# Get summary info\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.509365Z","iopub.execute_input":"2024-08-03T16:10:50.509782Z","iopub.status.idle":"2024-08-03T16:10:50.542084Z","shell.execute_reply.started":"2024-08-03T16:10:50.509745Z","shell.execute_reply":"2024-08-03T16:10:50.540185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variables are of different types. There are numerical 3x integer, 5x float, and  4x object. Notably, there are some null values present in several variables.","metadata":{}},{"cell_type":"code","source":"description = data.describe().T\n\ndescription.style.format('{:,.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.544255Z","iopub.execute_input":"2024-08-03T16:10:50.544769Z","iopub.status.idle":"2024-08-03T16:10:50.672513Z","shell.execute_reply.started":"2024-08-03T16:10:50.544725Z","shell.execute_reply":"2024-08-03T16:10:50.671347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comments and views almost reached a million, with some entries showing outliers. There are peaks in shares, likes, downloads, and comments in certain entries. These variables have very large standard deviations and extremely high maximum values compared to their quartile values.","metadata":{}},{"cell_type":"markdown","source":"### **Variables investigation**\n\nA good initial step in understanding the data is to examine the 'claim_status' variable. Start by determining the number of videos corresponding to each claim status.\n\n**Claim status**","metadata":{}},{"cell_type":"code","source":"# What are the different values for claim status and how many of each are in the data?\nclaim_status_counts = (data['claim_status'].value_counts())\nprint(claim_status_counts)\nprint()\nclaim_status_percentage = (claim_status_counts/claim_status_counts.sum())*100\nprint(claim_status_percentage)\nprint()\n\n# Specify the two classes we want to compare\nclass_1 = 'claim'\nclass_2 = 'opinion'\n\n# Calculate the difference between the counts of the two classes\ndifference = claim_status_counts[class_1] - claim_status_counts[class_2]\n\ntotal_counts = claim_status_counts.sum()\n    \n# Calculate the percentage difference\npercentage_difference = (difference / total_counts) * 100\n    \nprint(f\"The absolute difference between {class_1} and {class_2} is: {difference}\")\nprint(f\"The percentage difference between {class_1} and {class_2} is: {percentage_difference:.2f}%\")\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:50.674175Z","iopub.execute_input":"2024-08-03T16:10:50.674837Z","iopub.status.idle":"2024-08-03T16:10:50.691945Z","shell.execute_reply.started":"2024-08-03T16:10:50.674793Z","shell.execute_reply":"2024-08-03T16:10:50.690476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The counts for each claim status are well-balanced, that is reflected to a minimal percentage difference of 0.69%.","metadata":{}},{"cell_type":"markdown","source":"Next, examine the engagement trends associated with each different claim status.\n\nWe can start with Boolean masking to filter the data based on claim status, followed by calculating the mean and median view counts for each category.\n\n**Claim**","metadata":{}},{"cell_type":"code","source":"# What is the average view count of videos with \"claim\" status?\ndata_claim = data['claim_status'] =='claim'\n\nclaims = data[data['claim_status'] == 'claim']\nprint('Mean view count claims:', round(claims['video_view_count'].mean(),2))\nprint('Median view count claims:', claims['video_view_count'].median())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:50.693589Z","iopub.execute_input":"2024-08-03T16:10:50.693981Z","iopub.status.idle":"2024-08-03T16:10:50.721676Z","shell.execute_reply.started":"2024-08-03T16:10:50.693948Z","shell.execute_reply":"2024-08-03T16:10:50.720146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Opinion**","metadata":{}},{"cell_type":"code","source":"# What is the average view count of videos with \"opinion\" status?\ndata_opinion = data['claim_status'] =='opinion'\n#mean and median were in both categories really close to each other, almost identical.\n#there is great count differenece between claims and opinions\n\nopinions = data[data['claim_status'] == 'opinion']\nprint('Mean view count opinions:', opinions['video_view_count'].mean())\nprint('Median view count opinions:', opinions['video_view_count'].median())","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.723027Z","iopub.execute_input":"2024-08-03T16:10:50.723532Z","iopub.status.idle":"2024-08-03T16:10:50.743789Z","shell.execute_reply.started":"2024-08-03T16:10:50.723486Z","shell.execute_reply":"2024-08-03T16:10:50.742246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean and median values within each claim category are similar, but there is a significant difference in view counts between videos labeled as claims and those labeled as opinions.\n\nNow, examine trends associated with the ban status of the author.\n\nCalculate the number of videos for each combination of claim status and author ban status categories.","metadata":{}},{"cell_type":"code","source":"data.groupby(['claim_status', 'author_ban_status']).count()[['#']]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:50.745552Z","iopub.execute_input":"2024-08-03T16:10:50.746037Z","iopub.status.idle":"2024-08-03T16:10:50.775995Z","shell.execute_reply.started":"2024-08-03T16:10:50.745997Z","shell.execute_reply":"2024-08-03T16:10:50.77453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Claim videos are more strictly policed than opinion videos, requiring authors to adhere to a stricter set of rules when posting a claim compared to an opinion. It is important to note that we cannot determine whether claim videos are inherently more likely than opinion videos to result in author bans or if authors who post claim videos are simply more prone to violating terms of service.\n\nAdditionally, while this data allows us to draw conclusions about banned versus active authors, it does not provide insights into banned videos. We cannot ascertain if a specific video led to the ban, as banned authors may have posted other videos that complied with the terms of service.","metadata":{}},{"cell_type":"code","source":"# What's the median video share count of each author ban status?\ndata.groupby(['author_ban_status']).median(numeric_only=True)[['video_share_count']]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.77752Z","iopub.execute_input":"2024-08-03T16:10:50.777899Z","iopub.status.idle":"2024-08-03T16:10:50.800993Z","shell.execute_reply.started":"2024-08-03T16:10:50.777866Z","shell.execute_reply":"2024-08-03T16:10:50.799769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although banned accounts are fewer in number compared to active ones, they have higher median and average views, likes, and shares. Banned authors, in particular, have a median share count that is 33 times greater than that of active authors.","metadata":{}},{"cell_type":"code","source":"data.groupby(['author_ban_status']).agg(\n    {'video_view_count': ['count', 'mean', 'median'],\n     'video_like_count': ['count', 'mean', 'median'],\n     'video_share_count': ['count', 'mean', 'median']\n     })","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.802595Z","iopub.execute_input":"2024-08-03T16:10:50.802953Z","iopub.status.idle":"2024-08-03T16:10:50.838622Z","shell.execute_reply.started":"2024-08-03T16:10:50.802922Z","shell.execute_reply":"2024-08-03T16:10:50.837229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Banned authors and those under review receive significantly more views, likes, and shares compared to active authors. In most groups, the mean is substantially higher than the median, suggesting the presence of videos with exceptionally high engagement counts or large upper outliers.","metadata":{}},{"cell_type":"markdown","source":"Let's create engagement columns to gain a clearer understanding of their actual rates.","metadata":{}},{"cell_type":"code","source":"# Likes_per_view column\ndata['likes_per_view'] = data['video_like_count']/data['video_view_count']\n\n# Comments_per_view column\ndata['comments_per_view'] = data['video_comment_count']/data['video_view_count']\n\n# Shares_per_view column\ndata['shares_per_view'] = data['video_share_count']/ data['video_view_count']","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.840905Z","iopub.execute_input":"2024-08-03T16:10:50.841338Z","iopub.status.idle":"2024-08-03T16:10:50.853306Z","shell.execute_reply.started":"2024-08-03T16:10:50.841303Z","shell.execute_reply":"2024-08-03T16:10:50.851668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can analyze engagement metrics grouped by claim_status and author_ban_status","metadata":{}},{"cell_type":"code","source":"# Engagement metrics by claim_status & author_ban_status\ndata.groupby(['claim_status','author_ban_status']).agg(\n    {'likes_per_view': ['count','mean', 'median'],\n    'comments_per_view':['count','mean', 'median'],\n    'shares_per_view':['count','mean', 'median']})","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:50.859689Z","iopub.execute_input":"2024-08-03T16:10:50.860185Z","iopub.status.idle":"2024-08-03T16:10:50.902984Z","shell.execute_reply.started":"2024-08-03T16:10:50.860119Z","shell.execute_reply":"2024-08-03T16:10:50.901748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe that videos by banned authors and those under review generally attract significantly more views, likes, and shares compared to videos by non-banned authors. However, once a video is viewed, its engagement rate is more strongly influenced by its claim status than by the author's ban status.\n\nAdditionally, claim videos have a higher view rate compared to opinion videos, and they also receive a higher average rate of likes, indicating they are more favorably received. Moreover, claim videos garner more engagement through comments and shares than opinion videos.\n\nFor claim videos, banned authors achieve slightly higher likes-to-view and shares-to-view rates than active authors or those under review. In contrast, for opinion videos, active authors and those under review achieve higher engagement rates across all categories compared to banned authors.","metadata":{}},{"cell_type":"markdown","source":"###  Build visualizations\n\n#### **Video duration**\n\nCreate a box plot to analyze the range of values in video duration and a histogram to further investigate the distribution of these values.","metadata":{}},{"cell_type":"code","source":"# Colors from the Color Universal Design (CUD) palette\ncud_box_color = '#E69F00'  # Orange\ncud_hist_color = '#56B4E9'  # Sky Blue\n\n# Figure with two subplots side by side\nfig, axes = plt.subplots(1, 2, figsize=(15, 4))\n\n# First subplot: Boxplot\naxes[0].set_title('video_duration_sec')\nsns.boxplot(x=data['video_duration_sec'], ax=axes[0], color=cud_box_color)\n\n# Second subplot: Histogram \nsns.histplot(data['video_duration_sec'], bins=range(0, 61, 5), ax=axes[1], color=cud_hist_color)\naxes[1].set_title('Video duration histogram')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:36:38.22304Z","iopub.execute_input":"2024-08-03T16:36:38.224242Z","iopub.status.idle":"2024-08-03T16:36:38.857026Z","shell.execute_reply.started":"2024-08-03T16:36:38.224183Z","shell.execute_reply":"2024-08-03T16:36:38.855474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All videos have durations ranging from 5 to 60 seconds, with a uniformly distributed length.","metadata":{}},{"cell_type":"markdown","source":"#### **Video views**\n\nCreate a box plot to examine the spread of values in video views and histogram of this variable to explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n\n# Define labels for labels for view count categories from 0 to 1000k in increments of 100k\nlabels = [0] + [str(i) + 'k' for i in range(100, 1001, 100)]\n\naxes[0].set_title('video_view_count')\nsns.boxplot(x=data['video_view_count'], ax=axes[0], color=cud_box_color)\naxes[0].set_xticks(range(0, 10*10**5 + 1, 10**5)) # Set x-axis ticks from 0 to 1,000,000 in increments of 100,000\naxes[0].set_xticklabels(labels)\n\nsns.histplot(data['video_view_count'], bins=range(0,(10**6+1),10**5), ax=axes[1], color=cud_hist_color)\naxes[1].set_title('video_view_count histogram')\naxes[1].set_xticks(range(0, 10*10**5 + 1, 10**5))\naxes[1].set_xticklabels(labels)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:36:48.358862Z","iopub.execute_input":"2024-08-03T16:36:48.359325Z","iopub.status.idle":"2024-08-03T16:36:48.944868Z","shell.execute_reply.started":"2024-08-03T16:36:48.359281Z","shell.execute_reply":"2024-08-03T16:36:48.943383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This variable exhibits a highly uneven distribution, with more than half of the videos receiving fewer than 100,000 views. For view counts greater than 100,000, the distribution is uniform.","metadata":{}},{"cell_type":"markdown","source":"#### **Video likes**\n\nCreate a box plot to examine the spread of values in video likes and histogram to explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n\nlabels = [0] + [str(i) + 'k' for i in range(100, 701, 100)]\n\naxes[0].set_title('video_like_count')\nsns.boxplot(x=data['video_like_count'], ax=axes[0], color=cud_box_color)\naxes[0].set_xticks(range(0, 7*10**5 + 1, 10**5))\naxes[0].set_xticklabels(labels)\n\nsns.histplot(data['video_like_count'], bins=range(0, 7*10**5 + 1, 10**5), ax=axes[1], color=cud_hist_color)\naxes[1].set_title('Video like count histogram')\naxes[1].set_xticks(range(0, 7*10**5 + 1, 10**5))\naxes[1].set_xticklabels(labels)\n\nplt.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:37:34.45601Z","iopub.execute_input":"2024-08-03T16:37:34.457215Z","iopub.status.idle":"2024-08-03T16:37:35.193234Z","shell.execute_reply.started":"2024-08-03T16:37:34.457121Z","shell.execute_reply":"2024-08-03T16:37:35.191775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similar to view counts, there are significantly more videos with fewer than 100,000 likes compared to those with more. However, the distribution tapers off, with the data skewing to the right, resulting in many videos having extremely high like counts.","metadata":{}},{"cell_type":"markdown","source":"#### Video comments\n\nCreate a box plot to examine the spread of values in the video comments & histogram to further explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4), constrained_layout=True)\n\nhist_labels = [str(i) for i in range(0, 3001, 500)]\n\nax1.set_title('video_comment_count')\nsns.boxplot(x=data['video_comment_count'], ax=ax1, color=cud_box_color)\n\nsns.histplot(data['video_comment_count'], bins=range(0, 3001, 100), ax=ax2, color=cud_hist_color)\nax2.set_title('Video comment count histogram')\nax2.set_xticks(range(0, 3001, 500))\nax2.set_xticklabels(hist_labels);","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:37:39.480811Z","iopub.execute_input":"2024-08-03T16:37:39.48135Z","iopub.status.idle":"2024-08-03T16:37:40.250668Z","shell.execute_reply.started":"2024-08-03T16:37:39.4813Z","shell.execute_reply":"2024-08-03T16:37:40.249507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The majority of videos have comment counts clustered at the lower end of the range. Most videos have fewer than 100 comments, resulting in a highly right-skewed distribution.","metadata":{}},{"cell_type":"markdown","source":"#### Video shares\n\nCreate a boxplot to examine the spread of values of video shares and histogram to further explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 4), constrained_layout=True)\n\n# Labeling values in a more compact form, discards the remainder, giving the number of thousands.\nhist_labels = [f'{i//1000}k' for i in range(0, 270001, 20000)]\n\naxes[0].set_title('video_share_count')\nsns.boxplot(x=data['video_share_count'], ax=axes[0], color=cud_box_color)\naxes[0].set_xlabel('')  # Optionally remove x-axis label if not needed\n\nsns.histplot(data['video_share_count'], bins=range(0, 270001, 20000), ax=axes[1], color=cud_hist_color)\naxes[1].set_title('Video Share Count Histogram')\n\naxes[1].set_xticks(range(0, 270001, 20000))\naxes[1].set_xticklabels(hist_labels)\n\n# Optional: Rotate x-axis labels for better readability\naxes[1].tick_params(axis='x', rotation=45);","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:37:43.649764Z","iopub.execute_input":"2024-08-03T16:37:43.651024Z","iopub.status.idle":"2024-08-03T16:37:44.536944Z","shell.execute_reply.started":"2024-08-03T16:37:43.650958Z","shell.execute_reply":"2024-08-03T16:37:44.535499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most videos had fewer than 10,000 shares, resulting in a distribution that is highly right-skewed.","metadata":{}},{"cell_type":"markdown","source":"#### Video downloads\n\nCreate a boxplot to examine the spread of values in video downloads and histogram further explore the distribution.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 4), constrained_layout=True)\n\nhist_labels =  [str(i) for i in range(0,(15001),1000)]\n\naxes[0].set_title('video_download_count')\nsns.boxplot(x=data['video_download_count'], ax=axes[0], color=cud_box_color)\naxes[0].set_xlabel('')  # Optionally remove x-axis label if not needed\n\nsns.histplot(data['video_download_count'], bins=range(0,(15001),1000), ax=axes[1], color=cud_hist_color)\naxes[1].set_title('video_download_count Histogram')\n\naxes[1].set_xticks(range(0,(15001),1000))\naxes[1].set_xticklabels(hist_labels)\n\naxes[1].tick_params(axis='x', rotation=45);","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:37:47.715652Z","iopub.execute_input":"2024-08-03T16:37:47.716219Z","iopub.status.idle":"2024-08-03T16:37:48.633715Z","shell.execute_reply.started":"2024-08-03T16:37:47.716148Z","shell.execute_reply":"2024-08-03T16:37:48.632244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most videos were downloaded fewer than 500 times, though some received over 12,000 downloads. This indicates a significant rightward skew in the data.","metadata":{}},{"cell_type":"markdown","source":"#### **Claim status by verification status**\n\nCreate a histogram featuring four bars, with each bar representing a unique combination of claim status and verification status.","metadata":{}},{"cell_type":"code","source":"# Color Universal Design (CUD) palette\ncud_palette = ['#E69F00', '#56B4E9']\n\nplt.figure(figsize=(7, 4))\n\nsns.histplot(data=data,\n             x='claim_status',\n             hue='verified_status',\n             multiple='dodge',\n             shrink=0.9,\n             palette=cud_palette)\n\nplt.title('Claims by verification status histogram');","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:37:51.56199Z","iopub.execute_input":"2024-08-03T16:37:51.562535Z","iopub.status.idle":"2024-08-03T16:37:51.958057Z","shell.execute_reply.started":"2024-08-03T16:37:51.562491Z","shell.execute_reply":"2024-08-03T16:37:51.956747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are significantly fewer verified users compared to unverified ones; however, verified users are substantially more likely to post opinions.","metadata":{}},{"cell_type":"markdown","source":"#### Claim status by author ban status\n\nCreate a histogram to examine the count of each claim status for each author ban status.","metadata":{}},{"cell_type":"code","source":"cud_palette = {\n    'active': '#56B4E9',       # Sky Blue\n    'under review': '#E69F00', # Orange\n    'banned': '#E94E77'        # Fiery Red\n}\n\nfig = plt.figure(figsize=(8, 4))\n\nsns.histplot(data, x='claim_status', hue='author_ban_status',\n             multiple='dodge',\n             hue_order=['active', 'under review', 'banned'],\n             shrink=0.9,\n             palette=cud_palette,\n             alpha=0.5)\n\nplt.title('Claim status by author ban status');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For both claim and opinion videos, there are significantly more active authors than banned authors or those under review. However, the proportion of active authors is notably higher for opinion videos compared to claim videos. This suggests that authors who post claim videos are more likely to face review or banning.","metadata":{}},{"cell_type":"markdown","source":"#### **Median view counts by ban status**\n\nGenerate a bar plot with three bars, each representing a different author ban status. The height of each bar should reflect the median number of views for videos associated with that particular author ban status.","metadata":{}},{"cell_type":"code","source":"color_palette = {\n    'active': '#009E73',      # Green\n    'under review': '#F0E442', # Yellow\n    'banned': '#D55E00'       # Red\n}\n\n# Group and calculate the median values\nban_status_counts = data.groupby(['author_ban_status']).median(numeric_only=True).reset_index()\nfig = plt.figure(figsize=(6, 4))\nsns.barplot(\n    data=ban_status_counts,\n    x='author_ban_status',\n    y='video_view_count',\n    order=['active', 'under review', 'banned'],\n    palette=color_palette,\n    alpha=0.7\n)\nplt.title('Median view count by ban status');","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:56.954043Z","iopub.execute_input":"2024-08-03T16:10:56.954481Z","iopub.status.idle":"2024-08-03T16:10:57.265991Z","shell.execute_reply.started":"2024-08-03T16:10:56.954439Z","shell.execute_reply":"2024-08-03T16:10:57.264532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The median view counts for inactive authors are substantially higher than those for active authors. Considering that inactive authors are more susceptible to post claims and that their videos accumulate significantly more views overall than those of active authors,`video_view_count` may be an effective indicator of claim status.","metadata":{}},{"cell_type":"code","source":"data.groupby('claim_status')['video_view_count'].median()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:57.267892Z","iopub.execute_input":"2024-08-03T16:10:57.268432Z","iopub.status.idle":"2024-08-03T16:10:57.287195Z","shell.execute_reply.started":"2024-08-03T16:10:57.268381Z","shell.execute_reply":"2024-08-03T16:10:57.285787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In fact, a quick examination of the median view count by claim status supports this conclusion.","metadata":{}},{"cell_type":"markdown","source":"#### **Total views by claim status**\n\nCreate a pie graph that depicts the proportions of total views for claim videos and total views for opinion videos.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(3, 3))\nplt.pie(data.groupby('claim_status')['video_view_count'].sum(),labels=['claim', 'opinion'],\n    autopct='%1.1f%%',  # Show percentages on the pie chart\n    startangle=140  # Start angle to ensure consistent orientation\n)\nplt.title('Total Views by Video Claim Status');","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:57.289335Z","iopub.execute_input":"2024-08-03T16:10:57.289756Z","iopub.status.idle":"2024-08-03T16:10:57.424865Z","shell.execute_reply.started":"2024-08-03T16:10:57.289721Z","shell.execute_reply":"2024-08-03T16:10:57.422961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The overall view count is dominated by claim videos even though there are roughly the same number of each video in the dataset.","metadata":{}},{"cell_type":"markdown","source":"**Importance of Handling Outliers in Predictive Models**\n\nOutliers can pose significant challenges when constructing predictive models. For instance, if the goal is to forecast the view count of a video, those with exceptionally high view counts might skew the model's predictions. Additionally, outliers may signal issues in data collection or recording processes.\n\n**Objective of the TikTok Project**\n\nThe primary goal of the TikTok project is to develop a model that can predict whether a video is classified as a claim or an opinion. Our analysis has shown a strong correlation between a video's engagement level and its claim status. There is no evidence suggesting that the TikTok data contains inaccurately recorded values, and the distribution aligns with expected social media patterns: a small fraction of videos achieve extremely high engagement, reflecting the nature of viral content.\n\n**Importance of Identifying Outliers**\n\nThe approach to handling outliers should be tailored to the project's requirements, leveraging field knowledge to set appropriate thresholds. A common method for identifying outliers in a normally distributed dataset is to use the interquartile range (IQR), defining outliers as those beyond 1.5 times the IQR above the third quartile.\n\n**Adapting Outlier Detection for the TikTok Dataset**\n\nIn the TikTok dataset, the count variables are heavily right-skewed rather than normally distributed. To adjust the outlier threshold accordingly, one can calculate the median value for each variable and add 1.5 times the IQR. This results in a lower threshold compared to using the third quartile, better reflecting the dataset's skewed nature.\n\n**Steps:**\n\n1. Calculate the IQR of the column\n2. Calculate the median of the column\n3. Determine the outlier threshold using the formula: median + 1.5 * IQR.\n4. Count the number of videos with values in that column exceeding the outlier threshold.","metadata":{}},{"cell_type":"code","source":"# List of column names related to video metrics\ncount_cols = [\n    'video_view_count',\n    'video_like_count',\n    'video_share_count',\n    'video_download_count',\n    'video_comment_count',\n]\n\n# Iterate through each column in the list 'count_cols'\nfor column in count_cols:\n    # Calculate the first quartile (25th percentile) of the column data\n    q1 = data[column].quantile(0.25)\n    # Calculate the third quartile (75th percentile) of the column data\n    q3 = data[column].quantile(0.75)\n    # Calculate the interquartile range (IQR) as the difference between Q3 and Q1\n    iqr = q3 - q1\n    # Find the median (50th percentile) of the column data\n    median = data[column].median()\n    # Define an outlier threshold as 1.5 times the IQR above the median\n    outlier_threshold = median + 1.5 * iqr\n\n    # Count the number of values in the column that exceed the outlier threshold\n    outlier_count = (data[column] > outlier_threshold).sum()\n    # Print the count of outliers for the current column\n    print(f'Outliers of {column}:', outlier_count)\n ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:57.42777Z","iopub.execute_input":"2024-08-03T16:10:57.428467Z","iopub.status.idle":"2024-08-03T16:10:57.474914Z","shell.execute_reply.started":"2024-08-03T16:10:57.428408Z","shell.execute_reply":"2024-08-03T16:10:57.473282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Scatterplot**\n\nCreate a scatterplot of `video_view_count` versus `video_like_count` according to `claim_status`.","metadata":{}},{"cell_type":"code","source":"custom_palette = {'claim':'#56B4E9', 'opinion':'#E69F00'}\n\npalette = sns.color_palette(\"colorblind\", n_colors=2)\n\nsns.scatterplot(x=data[\"video_view_count\"], y=data[\"video_like_count\"],\n                hue=data[\"claim_status\"], s=10, alpha=.3, palette=palette)\nplt.title('Video_view_count vs. video_like_count by claim status')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:57.477388Z","iopub.execute_input":"2024-08-03T16:10:57.479241Z","iopub.status.idle":"2024-08-03T16:10:58.537179Z","shell.execute_reply.started":"2024-08-03T16:10:57.479147Z","shell.execute_reply":"2024-08-03T16:10:58.536028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a scatterplot of `video_view_count` versus `video_like_count` for opinions only","metadata":{}},{"cell_type":"code","source":"opinion = data[data['claim_status']=='opinion']\nsns.scatterplot(x=opinion[\"video_view_count\"],y=opinion[\"video_like_count\"],s=10,alpha=.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:58.538898Z","iopub.execute_input":"2024-08-03T16:10:58.539321Z","iopub.status.idle":"2024-08-03T16:10:58.862188Z","shell.execute_reply.started":"2024-08-03T16:10:58.539277Z","shell.execute_reply":"2024-08-03T16:10:58.860696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hypothesis Testing\n\nChecking for and handling missing values.","metadata":{}},{"cell_type":"code","source":"data.isna().sum()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:58.863852Z","iopub.execute_input":"2024-08-03T16:10:58.864341Z","iopub.status.idle":"2024-08-03T16:10:58.89092Z","shell.execute_reply.started":"2024-08-03T16:10:58.864282Z","shell.execute_reply":"2024-08-03T16:10:58.888935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with missing values\ndata = data.dropna(axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:58.892798Z","iopub.execute_input":"2024-08-03T16:10:58.893292Z","iopub.status.idle":"2024-08-03T16:10:58.914227Z","shell.execute_reply.started":"2024-08-03T16:10:58.893247Z","shell.execute_reply":"2024-08-03T16:10:58.912669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rows after handling missing values\ndata.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:58.915908Z","iopub.execute_input":"2024-08-03T16:10:58.916388Z","iopub.status.idle":"2024-08-03T16:10:58.942917Z","shell.execute_reply.started":"2024-08-03T16:10:58.916339Z","shell.execute_reply":"2024-08-03T16:10:58.94144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can explore the relationship between verified_status and video_view_count. One way to do this is by analyzing the average video_view_count for each verified_status group in the sample data.","metadata":{}},{"cell_type":"code","source":"data.groupby(\"verified_status\")[\"video_view_count\"].mean()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:58.944813Z","iopub.execute_input":"2024-08-03T16:10:58.945365Z","iopub.status.idle":"2024-08-03T16:10:58.961976Z","shell.execute_reply.started":"2024-08-03T16:10:58.945306Z","shell.execute_reply":"2024-08-03T16:10:58.960619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's recall the distinction between the null hypothesis and the alternative hypothesis and what are ours hypotheses for this data project.\n\n**Null Hypothesis (H0)**: There is no difference in the number of views between posts made by verified and unverified accounts on TikTok.\n\nAny observed difference in the sample data is attributed to chance or sampling variability.\n\n**Alternative Hypothesis (H1)**: There is a difference in the number of views between posts made by verified and unverified accounts on TikTok.\n\nAny observed difference in the sample data reflects a real difference in the population means. \n\nConduct a two-sample t-test:\n\n- State the null hypothesis and the alternative hypothesis.\n- Choose a significance level.\n- Find the p-value.\n- Reject or fail to reject the null hypothesis.\n\n**H0:** There is no difference in the number of views between posts made by verified and unverified accounts on TikTok.\n\nAny observed difference in the sample data is due to chance or sampling variability.\n\n**H1:** There is a difference in the number of views between posts made by verified and unverified accounts on TikTok.\n\nAny observed difference in the sample data is due to an actual difference in the corresponding population means.\n\nWe choose a 5% significance level.","metadata":{}},{"cell_type":"code","source":"# Save each sample in a variable\nnot_verified = data[data[\"verified_status\"] == \"not verified\"][\"video_view_count\"]\nverified = data[data[\"verified_status\"] == \"verified\"][\"video_view_count\"]\n\n# Apply a t-test using the two samples\nstats.ttest_ind(a=not_verified, b=verified, equal_var=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:58.963975Z","iopub.execute_input":"2024-08-03T16:10:58.964499Z","iopub.status.idle":"2024-08-03T16:10:58.99177Z","shell.execute_reply.started":"2024-08-03T16:10:58.964453Z","shell.execute_reply":"2024-08-03T16:10:58.990252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Given that the p-value is significantly smaller than the 5% significance level, you reject the null hypothesis. This indicates that there is a statistically significant difference in the mean video view counts between verified and unverified TikTok accounts.","metadata":{}},{"cell_type":"markdown","source":"### **Regression Analysis**\n\n\nCheck for and handle duplicates","metadata":{}},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:58.993677Z","iopub.execute_input":"2024-08-03T16:10:58.994145Z","iopub.status.idle":"2024-08-03T16:10:59.033274Z","shell.execute_reply.started":"2024-08-03T16:10:58.994101Z","shell.execute_reply":"2024-08-03T16:10:59.031982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Previously, we identified outliers in likes and comments using boxplots and histograms.\n\n\n**Video like count outliers**","metadata":{}},{"cell_type":"code","source":"# Calculate the 25th and 75th percentiles\nq25 = data['video_like_count'].quantile(0.25)\nq75 = data['video_like_count'].quantile(0.75)\n\n# Calculate the Interquartile Range (IQR)\niqr = q75 - q25\n\n# Determine the lower and upper limits for outliers\nlower_bound = q25 - 1.5 * iqr\nupper_bound = q75 + 1.5 * iqr\n\n# Cap the outliers at the upper limit\ndata.loc[data['video_like_count'] > upper_bound, 'video_like_count'] = upper_bound","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:59.035379Z","iopub.execute_input":"2024-08-03T16:10:59.03587Z","iopub.status.idle":"2024-08-03T16:10:59.048815Z","shell.execute_reply.started":"2024-08-03T16:10:59.035826Z","shell.execute_reply":"2024-08-03T16:10:59.047387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Video comment count outliers**","metadata":{}},{"cell_type":"code","source":"q25 = data['video_comment_count'].quantile(0.25)\nq75 = data['video_comment_count'].quantile(0.75)\n\niqr = q75 - q25\n\nlower_bound = q25 - 1.5 * iqr\nupper_bound = q75 + 1.5 * iqr\n\ndata.loc[data['video_comment_count'] > upper_bound, 'video_comment_count'] = upper_bound","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:59.050731Z","iopub.execute_input":"2024-08-03T16:10:59.051124Z","iopub.status.idle":"2024-08-03T16:10:59.063126Z","shell.execute_reply.started":"2024-08-03T16:10:59.051091Z","shell.execute_reply":"2024-08-03T16:10:59.061821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Class balance check**","metadata":{}},{"cell_type":"code","source":"# normalize= True return proportion rather than frequencies\ndata['verified_status'].value_counts(normalize=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:59.064602Z","iopub.execute_input":"2024-08-03T16:10:59.064949Z","iopub.status.idle":"2024-08-03T16:10:59.079109Z","shell.execute_reply.started":"2024-08-03T16:10:59.064919Z","shell.execute_reply":"2024-08-03T16:10:59.077851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Approximately 94.2% of the dataset comprises videos from unverified accounts, whereas only 5.8% are from verified accounts. This indicates a significant imbalance in the outcome variable.","metadata":{}},{"cell_type":"markdown","source":"If necessary, use resampling to achieve class balance in the outcome variable.","metadata":{}},{"cell_type":"code","source":"# Identify data points from majority and minority classes\ndata_majority = data[data[\"verified_status\"] == \"not verified\"]\ndata_minority = data[data[\"verified_status\"] == \"verified\"]\n\n# Upsample the minority class (which is \"verified\")\ndata_minority_upsampled = resample(\n    data_minority,\n    replace=True,                 # to sample with replacement\n    n_samples=len(data_majority), # to match majority class\n    random_state=0                # to create reproducible results\n)\n\n# Combine majority class with upsampled minority class\ndata_upsampled = pd.concat([data_majority, data_minority_upsampled]).reset_index(drop=True)\n\n# Display new class counts\nprint(data_upsampled['verified_status'].value_counts())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:59.08103Z","iopub.execute_input":"2024-08-03T16:10:59.081565Z","iopub.status.idle":"2024-08-03T16:10:59.137957Z","shell.execute_reply.started":"2024-08-03T16:10:59.081519Z","shell.execute_reply":"2024-08-03T16:10:59.136729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Determine the average length of video transcription texts for videos posted by verified accounts, and compare it to the average length of video transcription texts for videos posted by unverified accounts.","metadata":{}},{"cell_type":"code","source":"\ndata_upsampled.groupby('verified_status')['video_transcription_text'].apply(lambda texts: np.mean([len(text) for text in texts]))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:59.139618Z","iopub.execute_input":"2024-08-03T16:10:59.14007Z","iopub.status.idle":"2024-08-03T16:10:59.171682Z","shell.execute_reply.started":"2024-08-03T16:10:59.140027Z","shell.execute_reply":"2024-08-03T16:10:59.170249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract the length of each video_transcription_text and add it as a new column to the dataframe. This will allow the length to be used as a potential feature in the model.","metadata":{}},{"cell_type":"code","source":"# List comprehension iterates through each text in the column and calculate its length, assigning the results to the new text_length column\ndata_upsampled['text_length'] = [len(text) for text in data_upsampled['video_transcription_text']]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:10:59.173072Z","iopub.execute_input":"2024-08-03T16:10:59.173467Z","iopub.status.idle":"2024-08-03T16:10:59.208577Z","shell.execute_reply.started":"2024-08-03T16:10:59.173435Z","shell.execute_reply":"2024-08-03T16:10:59.207047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_upsampled.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:10:59.224234Z","iopub.execute_input":"2024-08-03T16:10:59.224667Z","iopub.status.idle":"2024-08-03T16:10:59.251599Z","shell.execute_reply.started":"2024-08-03T16:10:59.224629Z","shell.execute_reply":"2024-08-03T16:10:59.250172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the distribution of `video_transcription_text` length for videos posted by verified accounts compared to those posted by unverified accounts.","metadata":{}},{"cell_type":"code","source":"# Plot histogram of text lengths, differentiated by verification status\n\nc_palette = {'not verified':'#E69F00', 'verified':'#56B4E9'}\nsns.histplot(\n    data=data_upsampled, \n    x='text_length', \n    hue='verified_status', \n    multiple='stack', \n    stat='count', \n    kde=False, \n    element='bars', \n    palette=c_palette,\n    legend=True\n)\n\n# Customize plot\nplt.title('Transcription Text Length by account type')\nplt.xlabel('Text Length (Characters)');","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:38:19.466665Z","iopub.execute_input":"2024-08-03T16:38:19.467256Z","iopub.status.idle":"2024-08-03T16:38:20.975875Z","shell.execute_reply.started":"2024-08-03T16:38:19.46721Z","shell.execute_reply":"2024-08-03T16:38:20.974512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Correlations Analysis**","metadata":{}},{"cell_type":"markdown","source":"Now, let's create a correlation matrix to identify the variables with the highest correlations.","metadata":{}},{"cell_type":"code","source":"data_upsampled.corr(numeric_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.280508Z","iopub.execute_input":"2024-08-03T16:11:00.280877Z","iopub.status.idle":"2024-08-03T16:11:00.322457Z","shell.execute_reply.started":"2024-08-03T16:11:00.280846Z","shell.execute_reply":"2024-08-03T16:11:00.321259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation heatmap**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.heatmap(\n    data_upsampled[[\n        \"video_duration_sec\", \"claim_status\", \"author_ban_status\", \"video_view_count\", \n        \"video_like_count\", \"video_share_count\", \"video_download_count\", \"video_comment_count\", \"text_length\"\n    ]].corr(numeric_only=True), \n    annot=True, \n    cmap=\"coolwarm\"  # Using 'coolwarm' for colorblind-friendly colors\n)\nplt.title(\"Correlation heatmap\")\nplt.xticks(rotation=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.324399Z","iopub.execute_input":"2024-08-03T16:11:00.324896Z","iopub.status.idle":"2024-08-03T16:11:00.88099Z","shell.execute_reply.started":"2024-08-03T16:11:00.324852Z","shell.execute_reply":"2024-08-03T16:11:00.879584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the key assumptions for logistic regression is the absence of severe multicollinearity among the features. We need to keep this in mind as we analyze the heatmap and decide which features to include in our model.\n\n\nThe heatmap reveals a strong correlation between `video view count` and `video like count`, with a correlation coefficient of 0.86.\n\nTo meet this assumption, we could exclude the `video_like_count`.\n\nWe keep variables that measure video metrics: `video_view_count`, `video_share_count`, `video_download_count`, and `video_comment_count` as features.\n","metadata":{}},{"cell_type":"markdown","source":"**Variables selection**\n\nY and X variables","metadata":{}},{"cell_type":"code","source":"# target variable - Y\ny = data_upsampled[\"verified_status\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.88273Z","iopub.execute_input":"2024-08-03T16:11:00.883228Z","iopub.status.idle":"2024-08-03T16:11:00.889021Z","shell.execute_reply.started":"2024-08-03T16:11:00.88318Z","shell.execute_reply":"2024-08-03T16:11:00.887719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features - X\nX = data_upsampled[[\"video_duration_sec\", \"claim_status\", \"author_ban_status\", \"video_view_count\", \"video_share_count\", \"video_download_count\", \"video_comment_count\"]]\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.890647Z","iopub.execute_input":"2024-08-03T16:11:00.891103Z","iopub.status.idle":"2024-08-03T16:11:00.919779Z","shell.execute_reply.started":"2024-08-03T16:11:00.891046Z","shell.execute_reply":"2024-08-03T16:11:00.918358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The # and video_id columns are not chosen as features in this case, as they do not appear to aid in predicting whether a video presents a claim or an opinion.","metadata":{}},{"cell_type":"markdown","source":"Train-test split","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.921939Z","iopub.execute_input":"2024-08-03T16:11:00.922454Z","iopub.status.idle":"2024-08-03T16:11:00.9389Z","shell.execute_reply.started":"2024-08-03T16:11:00.922405Z","shell.execute_reply":"2024-08-03T16:11:00.93738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encode variables","metadata":{}},{"cell_type":"code","source":"# Check data types\nX_train.dtypes","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:00.941061Z","iopub.execute_input":"2024-08-03T16:11:00.941577Z","iopub.status.idle":"2024-08-03T16:11:00.951584Z","shell.execute_reply.started":"2024-08-03T16:11:00.941522Z","shell.execute_reply":"2024-08-03T16:11:00.950117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique `claim_status` values\nX_train[\"claim_status\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:00.953619Z","iopub.execute_input":"2024-08-03T16:11:00.954102Z","iopub.status.idle":"2024-08-03T16:11:00.968579Z","shell.execute_reply.started":"2024-08-03T16:11:00.954055Z","shell.execute_reply":"2024-08-03T16:11:00.967023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique `author_ban_status` values\nX_train[\"author_ban_status\"].unique()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:00.970597Z","iopub.execute_input":"2024-08-03T16:11:00.971083Z","iopub.status.idle":"2024-08-03T16:11:00.981888Z","shell.execute_reply.started":"2024-08-03T16:11:00.971039Z","shell.execute_reply":"2024-08-03T16:11:00.980645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As demonstrated earlier, the `claim_status` and `author_ban_status` features are currently of object data type. To utilize these categorical features with sklearn model implementations, they need to be converted to numeric values. One approach to achieve this is through one-hot encoding.","metadata":{}},{"cell_type":"markdown","source":"Encode categorical features in the training set","metadata":{}},{"cell_type":"code","source":"# Select training features to be encoded\nX_train_to_encode = X_train[[\"claim_status\", \"author_ban_status\"]]\n\n# Display few encoded rows\nX_train_to_encode.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:00.98352Z","iopub.execute_input":"2024-08-03T16:11:00.983864Z","iopub.status.idle":"2024-08-03T16:11:01.000099Z","shell.execute_reply.started":"2024-08-03T16:11:00.983835Z","shell.execute_reply":"2024-08-03T16:11:00.998704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize one-hot encoder for categorical features\nX_encoder = OneHotEncoder(drop='first', sparse_output=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.001693Z","iopub.execute_input":"2024-08-03T16:11:01.002123Z","iopub.status.idle":"2024-08-03T16:11:01.011123Z","shell.execute_reply.started":"2024-08-03T16:11:01.002073Z","shell.execute_reply":"2024-08-03T16:11:01.009606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit and transform the training features using the encoder\nX_train_encoded = X_encoder.fit_transform(X_train_to_encode)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.013276Z","iopub.execute_input":"2024-08-03T16:11:01.01378Z","iopub.status.idle":"2024-08-03T16:11:01.060644Z","shell.execute_reply.started":"2024-08-03T16:11:01.013734Z","shell.execute_reply":"2024-08-03T16:11:01.059251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get feature names from encoder\nX_encoder.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.062404Z","iopub.execute_input":"2024-08-03T16:11:01.062869Z","iopub.status.idle":"2024-08-03T16:11:01.071695Z","shell.execute_reply.started":"2024-08-03T16:11:01.062827Z","shell.execute_reply":"2024-08-03T16:11:01.070232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first few rows of encoded training features\nX_train_encoded","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.073416Z","iopub.execute_input":"2024-08-03T16:11:01.073895Z","iopub.status.idle":"2024-08-03T16:11:01.086364Z","shell.execute_reply.started":"2024-08-03T16:11:01.073847Z","shell.execute_reply":"2024-08-03T16:11:01.08496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Place encoded training features (which is currently an array) into a dataframe\nX_train_encoded_df = pd.DataFrame(data=X_train_encoded, columns=X_encoder.get_feature_names_out())\n\n# Display first few rows\nX_train_encoded_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.088059Z","iopub.execute_input":"2024-08-03T16:11:01.088512Z","iopub.status.idle":"2024-08-03T16:11:01.105202Z","shell.execute_reply.started":"2024-08-03T16:11:01.088477Z","shell.execute_reply":"2024-08-03T16:11:01.103865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first few rows of `X_train` with `claim_status` and `author_ban_status` columns dropped (since these features are being transformed to numeric)\nX_train.drop(columns=[\"claim_status\", \"author_ban_status\"]).head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.106888Z","iopub.execute_input":"2024-08-03T16:11:01.107382Z","iopub.status.idle":"2024-08-03T16:11:01.128683Z","shell.execute_reply.started":"2024-08-03T16:11:01.107337Z","shell.execute_reply":"2024-08-03T16:11:01.12728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate `X_train` and `X_train_encoded_df` to form the final dataframe for training data (`X_train_final`)\n# Remember to use `.reset_index(drop=True)` on `X_train` after removing `claim_status` and `author_ban_status`,\n# to ensure that the indices match those in `X_train_encoded_df` and `count_df`.\n\nX_train_final =pd.concat([X_train.drop(columns=['claim_status','author_ban_status']).reset_index(drop=True),X_train_encoded_df], axis=1)\n\nX_train_final.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.130243Z","iopub.execute_input":"2024-08-03T16:11:01.13071Z","iopub.status.idle":"2024-08-03T16:11:01.161601Z","shell.execute_reply.started":"2024-08-03T16:11:01.130666Z","shell.execute_reply":"2024-08-03T16:11:01.160297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verify the data type of the outcome variable.","metadata":{}},{"cell_type":"code","source":"y_train.dtypes","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.163044Z","iopub.execute_input":"2024-08-03T16:11:01.163453Z","iopub.status.idle":"2024-08-03T16:11:01.173344Z","shell.execute_reply.started":"2024-08-03T16:11:01.163418Z","shell.execute_reply":"2024-08-03T16:11:01.171947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get unique values of outcome variable","metadata":{}},{"cell_type":"code","source":"y_train.unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.175008Z","iopub.execute_input":"2024-08-03T16:11:01.175443Z","iopub.status.idle":"2024-08-03T16:11:01.189043Z","shell.execute_reply.started":"2024-08-03T16:11:01.175409Z","shell.execute_reply":"2024-08-03T16:11:01.187464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As demonstrated above, the outcome variable is currently of object data type. To convert it to a numeric format, one-hot encoding can be applied.","metadata":{}},{"cell_type":"code","source":"# Set up an encoder for one-hot encoding the categorical outcome variable\ny_encoder = OneHotEncoder(drop='first', sparse_output=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.190716Z","iopub.execute_input":"2024-08-03T16:11:01.191132Z","iopub.status.idle":"2024-08-03T16:11:01.197101Z","shell.execute_reply.started":"2024-08-03T16:11:01.191087Z","shell.execute_reply":"2024-08-03T16:11:01.195821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode the training outcome variable\n\n#  Adjusting the shape of `y_train` before passing into `.fit_transform()`, since it takes in 2D array\n#  `flatten()` - flattens the array returned by `.fit_transform()`, so that it can be used later to train the model\ny_train_final = y_encoder.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n\ny_train_final","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.198521Z","iopub.execute_input":"2024-08-03T16:11:01.198889Z","iopub.status.idle":"2024-08-03T16:11:01.2299Z","shell.execute_reply.started":"2024-08-03T16:11:01.198851Z","shell.execute_reply":"2024-08-03T16:11:01.228229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model building**","metadata":{}},{"cell_type":"code","source":"# Build a logistic regression model and fit it to the training dataset.\nlog_clf = LogisticRegression(random_state=0, max_iter=800).fit(X_train_final,y_train_final)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.231303Z","iopub.execute_input":"2024-08-03T16:11:01.231669Z","iopub.status.idle":"2024-08-03T16:11:01.491734Z","shell.execute_reply.started":"2024-08-03T16:11:01.231639Z","shell.execute_reply":"2024-08-03T16:11:01.490118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results and evaluation**","metadata":{}},{"cell_type":"code","source":"# Select the testing features that needs to be encoded\nX_test_to_encode = X_test[[\"claim_status\", \"author_ban_status\"]]\n\nX_test_to_encode.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.49383Z","iopub.execute_input":"2024-08-03T16:11:01.495485Z","iopub.status.idle":"2024-08-03T16:11:01.517966Z","shell.execute_reply.started":"2024-08-03T16:11:01.495398Z","shell.execute_reply":"2024-08-03T16:11:01.516298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the testing features using the encoder\nX_test_encoded = X_encoder.transform(X_test_to_encode)\n\nX_test_encoded","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.520081Z","iopub.execute_input":"2024-08-03T16:11:01.521646Z","iopub.status.idle":"2024-08-03T16:11:01.555835Z","shell.execute_reply.started":"2024-08-03T16:11:01.521577Z","shell.execute_reply":"2024-08-03T16:11:01.55426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Place encoded testing features (which is currently an array) into a dataframe\nX_test_encoded_df = pd.DataFrame(data=X_test_encoded, columns=X_encoder.get_feature_names_out())\n\nX_test_encoded_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.557827Z","iopub.execute_input":"2024-08-03T16:11:01.55937Z","iopub.status.idle":"2024-08-03T16:11:01.605124Z","shell.execute_reply.started":"2024-08-03T16:11:01.559305Z","shell.execute_reply":"2024-08-03T16:11:01.602957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first few rows of `X_test` with `claim_status` and `author_ban_status` columns dropped (since these features are being transformed to numeric)\nX_test.drop(columns=[\"claim_status\", \"author_ban_status\"]).head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.607184Z","iopub.execute_input":"2024-08-03T16:11:01.609451Z","iopub.status.idle":"2024-08-03T16:11:01.626797Z","shell.execute_reply.started":"2024-08-03T16:11:01.60941Z","shell.execute_reply":"2024-08-03T16:11:01.625425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate `X_test` and `X_test_encoded_df` to form the final dataframe for training data (`X_test_final`)\n# `.reset_index(drop=True)` to reset the index in X_test after dropping `claim_status`, and `author_ban_status`,\n# so that the indices align with those in `X_test_encoded_df` and `test_count_df`\nX_test_final = pd.concat([X_test.drop(columns=[\"claim_status\", \"author_ban_status\"]).reset_index(drop=True), X_test_encoded_df], axis=1)\n\nX_test_final.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.628438Z","iopub.execute_input":"2024-08-03T16:11:01.628877Z","iopub.status.idle":"2024-08-03T16:11:01.652441Z","shell.execute_reply.started":"2024-08-03T16:11:01.628837Z","shell.execute_reply":"2024-08-03T16:11:01.651257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate the logistic regression model by using it to generate predictions for the encoded testing set.","metadata":{}},{"cell_type":"code","source":"# Get predictions on the encoded testing set\ny_pred= log_clf.predict(X_test_final)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.653986Z","iopub.execute_input":"2024-08-03T16:11:01.654462Z","iopub.status.idle":"2024-08-03T16:11:01.675035Z","shell.execute_reply.started":"2024-08-03T16:11:01.654418Z","shell.execute_reply":"2024-08-03T16:11:01.672901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show the predictions for the encoded testing set.","metadata":{}},{"cell_type":"code","source":"# Display predictions\ny_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.677553Z","iopub.execute_input":"2024-08-03T16:11:01.678336Z","iopub.status.idle":"2024-08-03T16:11:01.689988Z","shell.execute_reply.started":"2024-08-03T16:11:01.678274Z","shell.execute_reply":"2024-08-03T16:11:01.688129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show the actual labels for the testing set.","metadata":{}},{"cell_type":"code","source":"# Display the true labels of the testing set\ny_test","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:01.692509Z","iopub.execute_input":"2024-08-03T16:11:01.701048Z","iopub.status.idle":"2024-08-03T16:11:01.722736Z","shell.execute_reply.started":"2024-08-03T16:11:01.700968Z","shell.execute_reply":"2024-08-03T16:11:01.720905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encode the true labels of the testing set into a format that allows for comparison with the predictions.","metadata":{}},{"cell_type":"code","source":"# Encode the testing outcome variable\n\n#   Adjusting the shape of `y_test` before passing into `.transform()`, since it takes in 2D array\n#   flatten()` flattens the array returned by `.transform()`, so that it can be used later to compare with predictions\n\ny_test_final = y_encoder.transform(y_test.values.reshape(-1, 1)).flatten()\n\ny_test_final","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.725059Z","iopub.execute_input":"2024-08-03T16:11:01.725976Z","iopub.status.idle":"2024-08-03T16:11:01.764916Z","shell.execute_reply.started":"2024-08-03T16:11:01.72592Z","shell.execute_reply":"2024-08-03T16:11:01.763147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's verify once more that the dimensions of the training and testing sets match, considering that additional features have been included.","metadata":{}},{"cell_type":"code","source":"# Get shape of each training and testing set\nX_train_final.shape, y_train_final.shape, X_test_final.shape, y_test_final.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.767702Z","iopub.execute_input":"2024-08-03T16:11:01.768551Z","iopub.status.idle":"2024-08-03T16:11:01.785893Z","shell.execute_reply.started":"2024-08-03T16:11:01.768457Z","shell.execute_reply":"2024-08-03T16:11:01.78501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize the outcomes of the model**","metadata":{}},{"cell_type":"code","source":"# Calculate values for confusion matrix\nlog_cm = confusion_matrix(y_test_final, y_pred, labels=log_clf.classes_)\n\n# Create display of confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=log_clf.classes_)\n\n# Plot confusion matrix\nlog_disp.plot(cmap='cividis');","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:01.7872Z","iopub.execute_input":"2024-08-03T16:11:01.787535Z","iopub.status.idle":"2024-08-03T16:11:02.138749Z","shell.execute_reply.started":"2024-08-03T16:11:01.787507Z","shell.execute_reply":"2024-08-03T16:11:02.137258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate a classification report that encompasses precision, recall, F1-score, and accuracy metrics to assess the performance of the logistic regression model.","metadata":{}},{"cell_type":"markdown","source":"**Classification report**","metadata":{}},{"cell_type":"code","source":"# Define your target labels\ntarget_labels = ['verified', 'not verified']\n\n# Generate the classification report as a dictionary\nreport_dict = classification_report(y_test_final, y_pred, target_names=target_labels, output_dict=True)\n\n# Convert the dictionary into a pandas DataFrame\nreport_df = pd.DataFrame(report_dict).transpose()\n\n# Print the DataFrame\nprint(report_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:02.140728Z","iopub.execute_input":"2024-08-03T16:11:02.141239Z","iopub.status.idle":"2024-08-03T16:11:02.187042Z","shell.execute_reply.started":"2024-08-03T16:11:02.141193Z","shell.execute_reply":"2024-08-03T16:11:02.185628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the feature names and corresponding model coefficients from a trained logistic regression model ","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame with feature names and model coefficients\n# log_clf is an instance of a logistic regression classifier that has been trained on a dataset.\npd.DataFrame(data={'Feature Name':log_clf.feature_names_in_,'Model Coefficients':log_clf.coef_[0]})","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:02.188979Z","iopub.execute_input":"2024-08-03T16:11:02.189549Z","iopub.status.idle":"2024-08-03T16:11:02.205043Z","shell.execute_reply.started":"2024-08-03T16:11:02.189505Z","shell.execute_reply":"2024-08-03T16:11:02.203607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Machine Learning for Video Classification**","metadata":{}},{"cell_type":"markdown","source":"## **PACE: Construct**","metadata":{"id":"kD8TsZ8jqri0"}},{"cell_type":"markdown","source":"### **Feature engineering**","metadata":{"id":"8i0spBspquCr"}},{"cell_type":"markdown","source":"Extract the length of each `video_transcription_text` and add this as a column to the dataframe, so that it can be used as a potential feature in the model.","metadata":{"id":"hb_u1c6_T1i-"}},{"cell_type":"code","source":"# Extract the length of each `video_transcription_text` and add this as a column to the dataframe\ndata['text_length'] = data['video_transcription_text'].str.len()\n\n# or use .apply() function with list comprehension\n# data['video_transcription_text'].apply(func= lambda x: len(x))","metadata":{"id":"8Yr9hhhVHeYY","execution":{"iopub.status.busy":"2024-08-03T16:11:02.206843Z","iopub.execute_input":"2024-08-03T16:11:02.20725Z","iopub.status.idle":"2024-08-03T16:11:02.231246Z","shell.execute_reply.started":"2024-08-03T16:11:02.207215Z","shell.execute_reply":"2024-08-03T16:11:02.229263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate the average text_length for claims and opinions.","metadata":{"id":"puP-V85lq06h"}},{"cell_type":"code","source":"# Calculate the average text_length for claims and opinions\ndata[['text_length','claim_status']].groupby('claim_status').mean()","metadata":{"id":"Vzg0J8UEJ1wx","execution":{"iopub.status.busy":"2024-08-03T16:11:02.233249Z","iopub.execute_input":"2024-08-03T16:11:02.233786Z","iopub.status.idle":"2024-08-03T16:11:02.255995Z","shell.execute_reply.started":"2024-08-03T16:11:02.233741Z","shell.execute_reply":"2024-08-03T16:11:02.254709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the distribution of `text_length` for claims and opinions.","metadata":{"id":"LGu7ipi4AJmP"}},{"cell_type":"code","source":"# Suppress the specific warning\n\n# Visualize the distribution of `text_length` for claims and opinions\n# Create two histograms in one plot\nc_palette = {'opinion':'#E69F00', 'claim':'#56B4E9'}\n\nsns.histplot(data=data, stat='count', hue='claim_status', multiple='dodge', x='text_length', \n              kde=False, legend=True, element='bars', palette=c_palette\n             )\nplt.title('Distribution of text_length for claims and opinions')\nplt.xlabel('Number of characters in (text_length)')\nplt.show()","metadata":{"id":"MSq136S3TIYe","execution":{"iopub.status.busy":"2024-08-03T16:31:20.449569Z","iopub.execute_input":"2024-08-03T16:31:20.450954Z","iopub.status.idle":"2024-08-03T16:31:21.507679Z","shell.execute_reply.started":"2024-08-03T16:31:20.450892Z","shell.execute_reply":"2024-08-03T16:31:21.505995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The letter count distributions for both claims and opinions are approximately normal with a slight right skew. Claim videos generally have a higher character count, averaging about 13 more characters than opinion videos, as noted in a previous analysis.","metadata":{}},{"cell_type":"markdown","source":"### **Feature selection and transformation**","metadata":{}},{"cell_type":"markdown","source":"Encode target and catgorical variables.","metadata":{}},{"cell_type":"code","source":"# Create a copy of the X data\nX=data.copy\n\n# Drop unnecessary columns\nX=data.drop(['#', 'video_id'],axis=1)\n\n# Encode target variable\nX['claim_status'] = X['claim_status'].map({'opinion':0, 'claim':1})\n\n# Dummy encode remaining categorical values\nX = pd.get_dummies(X, columns=['verified_status', 'author_ban_status'], \n                   drop_first=True)\nX.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:33:45.549141Z","iopub.execute_input":"2024-08-03T16:33:45.549686Z","iopub.status.idle":"2024-08-03T16:33:45.60623Z","shell.execute_reply.started":"2024-08-03T16:33:45.549649Z","shell.execute_reply":"2024-08-03T16:33:45.60456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Split the data**","metadata":{"id":"6frX3ATWZVgL"}},{"cell_type":"markdown","source":"Assign 'claim_status' as a target variable.","metadata":{}},{"cell_type":"code","source":"# Isolate target variable\ny=X['claim_status']","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.228851Z","iopub.execute_input":"2024-08-03T16:11:03.229397Z","iopub.status.idle":"2024-08-03T16:11:03.237417Z","shell.execute_reply.started":"2024-08-03T16:11:03.229349Z","shell.execute_reply":"2024-08-03T16:11:03.23575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Isolate the features.","metadata":{}},{"cell_type":"code","source":"# Isolate features\nX=X.drop(['claim_status'], axis=1)\n\nX.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.239017Z","iopub.execute_input":"2024-08-03T16:11:03.23942Z","iopub.status.idle":"2024-08-03T16:11:03.275354Z","shell.execute_reply.started":"2024-08-03T16:11:03.239388Z","shell.execute_reply":"2024-08-03T16:11:03.274016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create training, validation, and test sets**","metadata":{}},{"cell_type":"markdown","source":"Split data into training and testing sets, 80/20.","metadata":{"id":"i_3k0QfaNt1R"}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"id":"D5OpxNZYOISV","execution":{"iopub.status.busy":"2024-08-03T16:11:03.276979Z","iopub.execute_input":"2024-08-03T16:11:03.277474Z","iopub.status.idle":"2024-08-03T16:11:03.290948Z","shell.execute_reply.started":"2024-08-03T16:11:03.277427Z","shell.execute_reply":"2024-08-03T16:11:03.289585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the training set into training and validation sets, 75/25, to result in a final ratio of 60/20/20 for train/validate/test sets.","metadata":{"id":"rbpnEjop82zL"}},{"cell_type":"code","source":"# Split the training data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=0)","metadata":{"id":"A9O-DjLxOJvT","execution":{"iopub.status.busy":"2024-08-03T16:11:03.292736Z","iopub.execute_input":"2024-08-03T16:11:03.293239Z","iopub.status.idle":"2024-08-03T16:11:03.308369Z","shell.execute_reply.started":"2024-08-03T16:11:03.293193Z","shell.execute_reply":"2024-08-03T16:11:03.307131Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensure that the dimensions of the training, validation, and testing sets are consistent.","metadata":{}},{"cell_type":"code","source":"# Get shape of each training, validation, and testing set\nX_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.310011Z","iopub.execute_input":"2024-08-03T16:11:03.310523Z","iopub.status.idle":"2024-08-03T16:11:03.320493Z","shell.execute_reply.started":"2024-08-03T16:11:03.310467Z","shell.execute_reply":"2024-08-03T16:11:03.31932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confirm that the dimensions of the training, validation, and testing sets are in alignment.","metadata":{"id":"tJ60GPLdOMXr"}},{"cell_type":"markdown","source":"### **Tokenize text column**","metadata":{}},{"cell_type":"markdown","source":"The feature video_transcription_text is a text-based variable and is not categorical because it does not have a predetermined set of possible values. To convert this text into numerical features, a common method is to apply a bag-of-words approach, such as using the CountVectorizer.","metadata":{}},{"cell_type":"markdown","source":"CountVectorizer operates by dividing text into n-grams, which are sequences of n consecutive words. Each n-gram represents a sequence of adjacent words from the original text, capturing relationships between consecutive words.","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{"id":"3_es-Jh1atUz"}},{"cell_type":"code","source":"# Initialize  `CountVectorizer` object, which converts a collection of text to a matrix of token counts\ncount_vec = CountVectorizer(\n                ngram_range=(2, 3),    # Generates 2-grams and 3-grams (i.e., sequences of 2 or 3 consecutive words)\n                max_features=15,       # Limits the vocabulary to the top 15 most frequent n-grams.\n                stop_words='english'   # Excludes common English stop words (e.g., 'the', 'and') from the vocabulary.\n                )  \n# Dsiplay CountVectorizer\ncount_vec","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.322434Z","iopub.execute_input":"2024-08-03T16:11:03.322807Z","iopub.status.idle":"2024-08-03T16:11:03.337089Z","shell.execute_reply.started":"2024-08-03T16:11:03.322778Z","shell.execute_reply":"2024-08-03T16:11:03.335832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit the vectorizer to the training data to generate the n-grams and transform the data to count their occurrences. Ensure that the vectorizer is fitted only on the training data and not on the validation or test data.","metadata":{}},{"cell_type":"code","source":"# Fit the vectorizer to the training data to learn the vocabulary and generate n-grams,\n# then transform the training text data into a numerical format with occurrence counts.\n# Convert the resulting sparse matrix to a dense array.\ncount_data = count_vec.fit_transform(X_train['video_transcription_text']).toarray()\n\ncount_data","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.339015Z","iopub.execute_input":"2024-08-03T16:11:03.33958Z","iopub.status.idle":"2024-08-03T16:11:03.831681Z","shell.execute_reply.started":"2024-08-03T16:11:03.339534Z","shell.execute_reply":"2024-08-03T16:11:03.830255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Place the numerical representation of `video_transcription_text` from training set into a dataframe\ncount_df = pd.DataFrame(data=count_data, columns=count_vec.get_feature_names_out())\n\n# Display first few rows\ncount_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:03.833143Z","iopub.execute_input":"2024-08-03T16:11:03.833592Z","iopub.status.idle":"2024-08-03T16:11:03.852597Z","shell.execute_reply.started":"2024-08-03T16:11:03.833558Z","shell.execute_reply":"2024-08-03T16:11:03.851241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine `X_train` and `count_df` to form the final dataframe for training data (`X_train_final`)\n# `.reset_index(drop=True)` to reset the index in X_train after dropping `video_transcription_text`,\n# so that the indices align with those in `X_train` and `count_df`\nX_train_final = pd.concat([X_train.drop(columns=['video_transcription_text']).reset_index(drop=True), count_df], axis=1)\n\n# Display first few rows\nX_train_final.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:03.854802Z","iopub.execute_input":"2024-08-03T16:11:03.855236Z","iopub.status.idle":"2024-08-03T16:11:03.896896Z","shell.execute_reply.started":"2024-08-03T16:11:03.855181Z","shell.execute_reply":"2024-08-03T16:11:03.89544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine the original training features (excluding 'video_transcription_text') with the new numerical features \n# derived from the vectorizer into a single DataFrame. \n# Reset the index to ensure proper alignment with `count_df` and concatenate along the columns axis.\nX_train_final = pd.concat([X_train.drop(columns=['video_transcription_text']).reset_index(drop=True), count_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:11:03.898615Z","iopub.execute_input":"2024-08-03T16:11:03.89899Z","iopub.status.idle":"2024-08-03T16:11:03.909966Z","shell.execute_reply.started":"2024-08-03T16:11:03.898954Z","shell.execute_reply":"2024-08-03T16:11:03.908613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract numerical features from `video_transcription_text` in the testing set\nvalidation_count_data = count_vec.transform(X_val['video_transcription_text']).toarray()\nvalidation_count_data","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:03.911784Z","iopub.execute_input":"2024-08-03T16:11:03.912173Z","iopub.status.idle":"2024-08-03T16:11:04.048822Z","shell.execute_reply.started":"2024-08-03T16:11:03.912125Z","shell.execute_reply":"2024-08-03T16:11:04.047275Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Place the numerical representation of `video_transcription_text` from validation set into a dataframe\nvalidation_count_df = pd.DataFrame(data=validation_count_data, columns=count_vec.get_feature_names_out())\nvalidation_count_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:04.050792Z","iopub.execute_input":"2024-08-03T16:11:04.051191Z","iopub.status.idle":"2024-08-03T16:11:04.069984Z","shell.execute_reply.started":"2024-08-03T16:11:04.051132Z","shell.execute_reply":"2024-08-03T16:11:04.068604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine `X_val` and `validation_count_df` to crate the final dataframe for validation data (`X_val_final`)\n# `.reset_index(drop=True)`ensures that the index is reset in `X_val` after dropping the `video_transcription_text` column,\n# aligning the indices with those in `validation_count_df`.\nX_val_final = pd.concat([X_val.drop(columns=['video_transcription_text']).reset_index(drop=True), validation_count_df], axis=1)\n\n# Display first few rows\nX_val_final.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:04.071605Z","iopub.execute_input":"2024-08-03T16:11:04.072008Z","iopub.status.idle":"2024-08-03T16:11:04.111066Z","shell.execute_reply.started":"2024-08-03T16:11:04.071975Z","shell.execute_reply":"2024-08-03T16:11:04.1098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apply the same vectorizer to the test data to obtain n-gram counts. Ensure that the vectorizer is only used for transformation and not refitted.","metadata":{}},{"cell_type":"code","source":"# Convert `video_transcription_text` from the test set into numerical features using the fitted vectorizer\ntest_count_data = count_vec.transform(X_test['video_transcription_text']).toarray()\n\n# Create a DataFrame from the numerical features, using the feature names provided by the vectorizer\ntest_count_df = pd.DataFrame(data=test_count_data, columns=count_vec.get_feature_names_out())\n\n# Combine the transformed numerical features with the remaining columns from `X_test` to create the final testing dataset\nX_test_final = pd.concat([X_test.drop(columns=['video_transcription_text']\n                                      ).reset_index(drop=True), test_count_df], axis=1)\nX_test_final.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:11:04.112637Z","iopub.execute_input":"2024-08-03T16:11:04.113001Z","iopub.status.idle":"2024-08-03T16:11:04.28088Z","shell.execute_reply.started":"2024-08-03T16:11:04.112969Z","shell.execute_reply":"2024-08-03T16:11:04.279589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Random Forest model**","metadata":{"id":"HdBwwccoP0SU"}},{"cell_type":"markdown","source":"Fit a random forest model to the training set. Use cross-validation to tune the hyperparameters and select the model that performs best on recall.","metadata":{"id":"ty8ieBkDBH4g"}},{"cell_type":"code","source":"# Instantiate the random forest classifier with a fixed random seed for reproducibility\nrf = RandomForestClassifier(random_state=0)\n\n# Define a dictionary with hyperparameters to tune for cross-validation\ncv_params = {\n    'max_depth': [5, 7, None],              # Options for the maximum depth of the tree\n    'max_features': [0.3, 0.6],             # Proportion of features to consider for splits\n    # 'max_features': 'auto'                # Alternative option for feature selection\n    'max_samples': [0.7],                   # Proportion of samples to use for fitting each base estimator\n    'min_samples_leaf': [1, 2],             # Minimum number of samples required to be at a leaf node\n    'min_samples_split': [2, 3],            # Minimum number of samples required to split an internal node\n    'n_estimators': [75, 100, 200],         # Number of base estimators in the ensemble\n}\n\n# Define a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\n\n# Instantiate the GridSearchCV object\nrf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='recall')","metadata":{"id":"sNcke2SNvZrN","execution":{"iopub.status.busy":"2024-08-03T16:11:04.282433Z","iopub.execute_input":"2024-08-03T16:11:04.282851Z","iopub.status.idle":"2024-08-03T16:11:04.291584Z","shell.execute_reply.started":"2024-08-03T16:11:04.282816Z","shell.execute_reply":"2024-08-03T16:11:04.290174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Fit the model\nrf_cv.fit(X_train_final, y_train)","metadata":{"id":"ZG3B_POzPh1s","execution":{"iopub.status.busy":"2024-08-03T16:11:04.293303Z","iopub.execute_input":"2024-08-03T16:11:04.293686Z","iopub.status.idle":"2024-08-03T16:22:07.900569Z","shell.execute_reply.started":"2024-08-03T16:11:04.293655Z","shell.execute_reply":"2024-08-03T16:22:07.899233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output the best recall score achieved during cross-validation\nrf_cv.best_score_","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:22:07.902517Z","iopub.execute_input":"2024-08-03T16:22:07.902979Z","iopub.status.idle":"2024-08-03T16:22:07.911717Z","shell.execute_reply.started":"2024-08-03T16:22:07.902937Z","shell.execute_reply":"2024-08-03T16:22:07.910239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output the best hyperparameters found during cross-validation\nrf_cv.best_params_","metadata":{"id":"-qzIDhk-Pq62","scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:22:07.913332Z","iopub.execute_input":"2024-08-03T16:22:07.913746Z","iopub.status.idle":"2024-08-03T16:22:07.926605Z","shell.execute_reply.started":"2024-08-03T16:22:07.913712Z","shell.execute_reply":"2024-08-03T16:22:07.925229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model demonstrates exceptional performance, achieving an average recall score of 0.995 across five cross-validation folds. Upon verifying the precision score to ensure the model is not classifying all samples as claims, it is evident that the model is making nearly perfect classifications.","metadata":{}},{"cell_type":"markdown","source":"### XGBoost model","metadata":{}},{"cell_type":"code","source":"# Instantiate the XGBoost classifier\nxgb = XGBClassifier(objective='binary:logistic', random_state=0)\n\n# Create a dictionary of hyperparameters to tune\ncv_params = {'max_depth': [4,8,12],\n             'min_child_weight': [3, 5],\n             'learning_rate': [0.01, 0.1],\n             'n_estimators': [300, 500]\n             }\n\n# Define a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\n\n# Instantiate the GridSearchCV object\nxgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=5, refit='recall')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:22:07.928085Z","iopub.execute_input":"2024-08-03T16:22:07.928476Z","iopub.status.idle":"2024-08-03T16:22:07.944842Z","shell.execute_reply.started":"2024-08-03T16:22:07.928444Z","shell.execute_reply":"2024-08-03T16:22:07.94342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nxgb_cv.fit(X_train_final, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:22:07.946542Z","iopub.execute_input":"2024-08-03T16:22:07.946967Z","iopub.status.idle":"2024-08-03T16:23:44.868786Z","shell.execute_reply.started":"2024-08-03T16:22:07.946926Z","shell.execute_reply":"2024-08-03T16:23:44.867471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine best recall score\nxgb_cv.best_score_","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:44.870546Z","iopub.execute_input":"2024-08-03T16:23:44.870905Z","iopub.status.idle":"2024-08-03T16:23:44.879434Z","shell.execute_reply.started":"2024-08-03T16:23:44.87087Z","shell.execute_reply":"2024-08-03T16:23:44.877889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv.best_params_","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:44.881268Z","iopub.execute_input":"2024-08-03T16:23:44.881886Z","iopub.status.idle":"2024-08-03T16:23:44.89534Z","shell.execute_reply.started":"2024-08-03T16:23:44.881831Z","shell.execute_reply":"2024-08-03T16:23:44.893705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model delivers exceptional performance. Despite its recall score being slightly lower than the random forest model's, its precision score is flawless.","metadata":{}},{"cell_type":"markdown","source":"## **PACE: Execute**","metadata":{"id":"_HGsWfEOeWPm"}},{"cell_type":"markdown","source":"### Model evaluation\n\nEvaluate models against validation criteria.","metadata":{"id":"GyepBhCTa1Yx"}},{"cell_type":"markdown","source":"#### **Random forest model**","metadata":{"id":"vlAQZSQrRg9l"}},{"cell_type":"code","source":"# Use the random forest \"best estimator\" model to get predictions on the encoded testing set\ny_pred = rf_cv.best_estimator_.predict(X_val_final)","metadata":{"id":"mdTCEa_cRH8f","execution":{"iopub.status.busy":"2024-08-03T16:23:44.897Z","iopub.execute_input":"2024-08-03T16:23:44.897506Z","iopub.status.idle":"2024-08-03T16:23:44.996773Z","shell.execute_reply.started":"2024-08-03T16:23:44.897459Z","shell.execute_reply":"2024-08-03T16:23:44.995333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the predictions on the encoded testing set.","metadata":{"id":"As6nmV9xRLa-"}},{"cell_type":"code","source":"# Display the predictions on the encoded testing set\ny_pred","metadata":{"id":"t8ppFvJXRL13","execution":{"iopub.status.busy":"2024-08-03T16:23:44.998184Z","iopub.execute_input":"2024-08-03T16:23:44.998551Z","iopub.status.idle":"2024-08-03T16:23:45.007273Z","shell.execute_reply.started":"2024-08-03T16:23:44.99852Z","shell.execute_reply":"2024-08-03T16:23:45.005733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the true labels of the testing set.","metadata":{"id":"kR54Eel1RSUk"}},{"cell_type":"code","source":"# Display the true labels of the testing set\ny_val","metadata":{"id":"7-mCyVmLRSuz","execution":{"iopub.status.busy":"2024-08-03T16:23:45.008663Z","iopub.execute_input":"2024-08-03T16:23:45.009038Z","iopub.status.idle":"2024-08-03T16:23:45.026028Z","shell.execute_reply.started":"2024-08-03T16:23:45.009006Z","shell.execute_reply":"2024-08-03T16:23:45.024699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a confusion matrix to visualize the results of the classification model.","metadata":{"id":"rGbqgRDFRVZi"}},{"cell_type":"code","source":"# Compute values for confusion matrix\nlog_cm = confusion_matrix(y_val, y_pred)\n\n# Create display of confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n\n# Plot confusion matrix\nlog_disp.plot(cmap='cividis')\n\nplt.title('Random Forest - validation set');","metadata":{"id":"_YJeJuzvRYPf","execution":{"iopub.status.busy":"2024-08-03T16:23:45.027472Z","iopub.execute_input":"2024-08-03T16:23:45.027814Z","iopub.status.idle":"2024-08-03T16:23:45.345378Z","shell.execute_reply.started":"2024-08-03T16:23:45.027785Z","shell.execute_reply":"2024-08-03T16:23:45.343976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the confusion matrix:\n\n- The upper-left quadrant represents the count of true negatives, indicating the number of opinions correctly classified as opinions by the model.\n- The upper-right quadrant shows the number of false positives, which are opinions incorrectly classified as claims.\n- The lower-left quadrant reflects the number of false negatives, representing claims incorrectly classified as opinions.\n- The lower-right quadrant displays the count of true positives, representing claims correctly classified as claims.\nAn ideal model would result in only true negatives and true positives, with no false negatives or false positives.\n\nAs illustrated by the confusion matrix, this model achieves perfect performance with no false negatives.","metadata":{}},{"cell_type":"markdown","source":"Create a classification report that includes precision, recall, f1-score, and accuracy metrics to evaluate the performance of the model.","metadata":{"id":"C2dugw11RiIK"}},{"cell_type":"code","source":"# Create classification report for random forest model\ntarget_labels =['opinion', 'claim']\nprint(classification_report(y_val, y_pred, target_names=target_labels))","metadata":{"id":"kB8e7wfhRrAl","scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T16:23:45.346934Z","iopub.execute_input":"2024-08-03T16:23:45.347445Z","iopub.status.idle":"2024-08-03T16:23:45.37365Z","shell.execute_reply.started":"2024-08-03T16:23:45.347407Z","shell.execute_reply":"2024-08-03T16:23:45.372324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The classification report above demonstrates that the random forest model achieved nearly perfect scores. According to the confusion matrix, there were 4 misclassifications in total, that come from false positives quadrant.","metadata":{"id":"4PrZTQEXwrX6"}},{"cell_type":"markdown","source":"#### **XGBoost model**","metadata":{}},{"cell_type":"code","source":"#Evaluate XGBoost model\ny_pred = xgb_cv.best_estimator_.predict(X_val_final)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:45.375239Z","iopub.execute_input":"2024-08-03T16:23:45.375709Z","iopub.status.idle":"2024-08-03T16:23:45.414925Z","shell.execute_reply.started":"2024-08-03T16:23:45.375667Z","shell.execute_reply":"2024-08-03T16:23:45.413731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:45.416813Z","iopub.execute_input":"2024-08-03T16:23:45.417203Z","iopub.status.idle":"2024-08-03T16:23:45.423954Z","shell.execute_reply.started":"2024-08-03T16:23:45.417172Z","shell.execute_reply":"2024-08-03T16:23:45.423059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute values for confusion matrix\nlog_cm = confusion_matrix(y_val, y_pred)\n\n# Create display of confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n\n# Plot confusion matrix\nlog_disp.plot()\n\n# Display plot\nplt.title('XGBoost - validation set');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:45.425331Z","iopub.execute_input":"2024-08-03T16:23:45.425916Z","iopub.status.idle":"2024-08-03T16:23:45.741559Z","shell.execute_reply.started":"2024-08-03T16:23:45.425881Z","shell.execute_reply":"2024-08-03T16:23:45.74021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create classification report for XGBoost model\ntarget_labels =['opinion', 'claim']\nprint(classification_report(y_val, y_pred, target_names=target_labels))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:45.743039Z","iopub.execute_input":"2024-08-03T16:23:45.74385Z","iopub.status.idle":"2024-08-03T16:23:45.767519Z","shell.execute_reply.started":"2024-08-03T16:23:45.743814Z","shell.execute_reply":"2024-08-03T16:23:45.766219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results from the XGBoost model were almost flawless, but it frequently produced false negatives. Since identifying claims is crucial, it’s essential for the model to effectively capture all actual claim videos. The random forest model, with its superior recall score, is therefore considered the best-performing model.","metadata":{}},{"cell_type":"markdown","source":"### **Use champion model to predict on test data**","metadata":{"id":"RhYr1O9jSN7O"}},{"cell_type":"markdown","source":"Both the Random Forest and XGBoost model architectures yielded near-perfect results. However, in this instance, the Random Forest model performed slightly better, making it the preferred model.","metadata":{}},{"cell_type":"code","source":"# Use champion model to predict on test data\ny_pred = rf_cv.best_estimator_.predict(X_test_final)","metadata":{"id":"VJj1uNRqSQpG","execution":{"iopub.status.busy":"2024-08-03T16:23:45.769136Z","iopub.execute_input":"2024-08-03T16:23:45.76968Z","iopub.status.idle":"2024-08-03T16:23:45.857871Z","shell.execute_reply.started":"2024-08-03T16:23:45.769646Z","shell.execute_reply":"2024-08-03T16:23:45.856655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute values for confusion matrix\nlog_cm = confusion_matrix(y_test, y_pred)\n\n# Create display of confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n\n# Plot confusion matrix\nlog_disp.plot(cmap='cividis')\n\n# Display plot\nplt.title('Random forest - test set');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:45.860082Z","iopub.execute_input":"2024-08-03T16:23:45.860585Z","iopub.status.idle":"2024-08-03T16:23:46.122022Z","shell.execute_reply.started":"2024-08-03T16:23:45.860542Z","shell.execute_reply":"2024-08-03T16:23:46.120594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Feature importances of champion model**\n","metadata":{"id":"2vpvCa5rSVqR"}},{"cell_type":"code","source":"# Extract the feature importances from the best estimator of the random forest cross-validation model\nimportances = rf_cv.best_estimator_.feature_importances_\n\n# Create a Pandas Series to hold the feature importances, using the column names from the test dataset as the index\nrf_importances = pd.Series(importances, index=X_test_final.columns)\n\n# Sort the feature importances in descending order and select the top 10\ntop_10_rf_importances = rf_importances.sort_values(ascending=False).head(10).sort_values(ascending=True)\n\n# Colorblind-friendly color\ncolorblind_color = \"#E69F00\"\n\n# Create the horizontal bar plot\nfig, ax = plt.subplots()\ntop_10_rf_importances.plot.barh(ax=ax, color=colorblind_color)  # Create a horizontal bar plot\n\n# Set the plot title and labels\nax.set_title('Top 10 Feature Importances of champion model', fontsize=12)\nax.set_xlabel('Mean Decrease in Impurity')\nax.set_ylabel('Feature')\n\n# Set y-ticks font size\nax.tick_params(axis='y', labelsize=9)\nax.tick_params(axis='x', labelsize=9)\n\n# Adjust layout for better fit\nfig.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:23:46.123603Z","iopub.execute_input":"2024-08-03T16:23:46.123988Z","iopub.status.idle":"2024-08-03T16:23:46.490551Z","shell.execute_reply.started":"2024-08-03T16:23:46.123953Z","shell.execute_reply":"2024-08-03T16:23:46.48925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most predictive features were all related to the engagement levels generated by the video. This aligns with prior exploratory data analysis, which indicated a strong correlation between engagement metrics and the model's predictions.","metadata":{}},{"cell_type":"markdown","source":"###  Final Project Conclusion","metadata":{"id":"ill21hQ4ej9-"}},{"cell_type":"markdown","source":"**Recommendation on Model Usage:**\n\nWe recommend using the current model due to its exceptional performance across both validation and test datasets. It consistently achieved high precision and F1 scores, reflecting its strong capability in accurately classifying both claims and opinions.\n\n**Model Functionality and Prediction Mechanism:**\n\nThe model's effectiveness stems from its reliance on user engagement metrics. It primarily classifies videos based on features such as the number of views, likes, shares, and downloads. These engagement indicators were found to be the most predictive features for determining the video classifications.\n\n**Future Feature Engineering:**\n\nGiven the model's near-perfect performance, there is no immediate need for additional feature engineering. However, for potential future improvements, incorporating features such as the number of times a video was reported and the total number of user reports across all videos by each author could be beneficial. These additional metrics might provide further insights and enhance the model’s predictive capabilities.","metadata":{}},{"cell_type":"markdown","source":"It is important to acknowledge that there are instances when the data we have may not effectively predict the target variable. This is a natural occurrence in data science. While machine learning is a robust and valuable tool, it is not infallible. If the data lacks a meaningful predictive signal, even the most advanced algorithms will struggle to produce reliable and accurate predictions. Embracing this reality and drawing appropriate conclusions is an essential aspect of our analytical process.","metadata":{}}]}